# BERT-based Personality Type Prediction

This project demonstrates how to use a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model for predicting personality types based on textual data using the Myers-Briggs Type Indicator (MBTI) classification.

## Overview
The project involves:

Fine-tuning a BERT model for sequence classification on MBTI personality type prediction.
Preprocessing textual data using the Hugging Face transformers library.
Training the model on a labeled dataset of MBTI personality type posts.
Evaluating the model's performance using metrics like accuracy, loss, and confusion matrix.
Providing inference capabilities to predict personality types for new text inputs.
